{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "1ezWHbAHHVFf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"Alphabets_data.csv\")"
      ],
      "metadata": {
        "id": "7LC99C8FJ4Rf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic structure\n",
        "print(\"Dataset Summary:\")\n",
        "print(f\"Number of samples: {df.shape[0]}\")\n",
        "print(f\"Number of features (including target): {df.shape[1]}\")\n",
        "print(f\"Target classes: {sorted(df['letter'].unique())}\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum().sum()\n",
        "print(f\"Total missing values: {missing_values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0sDOgHwVMP3",
        "outputId": "2754cb85-1994-487c-b596-62b27e10a42b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Summary:\n",
            "Number of samples: 20000\n",
            "Number of features (including target): 17\n",
            "Target classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
            "Total missing values: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and target\n",
        "X = df.drop('letter', axis=1).values.astype(np.float32)\n",
        "y = df['letter'].values\n",
        "\n",
        "# Encode target labels (A-Z â†’ 0â€“25)\n",
        "label_map = {label: idx for idx, label in enumerate(sorted(np.unique(y)))}\n",
        "y_encoded = np.array([label_map[label] for label in y])\n",
        "\n",
        "# Normalize feature values to range [0, 1]\n",
        "X_min = X.min(axis=0)\n",
        "X_max = X.max(axis=0)\n",
        "X_normalized = (X - X_min) / (X_max - X_min + 1e-7)"
      ],
      "metadata": {
        "id": "YDLfiHkPVl1-"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_normalized.shape, y_encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7va2WKp6V4sp",
        "outputId": "db2b3ac1-e369-4da9-cbe7-838d63c54378"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 16), (20000,))"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomized train-test split (80% train, 20% test)\n",
        "np.random.seed(42)\n",
        "indices = np.arange(len(X_normalized))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "X_shuffled = X_normalized[indices]\n",
        "y_shuffled = y_encoded[indices]\n",
        "\n",
        "split_index = int(0.8 * len(X_shuffled))\n",
        "X_train = X_shuffled[:split_index]\n",
        "X_test = X_shuffled[split_index:]\n",
        "y_train = y_shuffled[:split_index]\n",
        "y_test = y_shuffled[split_index:]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Wrap into TensorDataset\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "1RUWlMC-WRKX"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlphabetClassifier(nn.Module):\n",
        "    def __init__(self, input_size=16, hidden1=64, hidden2=32, output_size=26, activation=nn.ReLU):\n",
        "        super(AlphabetClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden1)\n",
        "        self.act1 = activation()\n",
        "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
        "        self.act2 = activation()\n",
        "        self.fc3 = nn.Linear(hidden2, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act1(self.fc1(x))\n",
        "        x = self.act2(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "50FqkvcBYJfg"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = AlphabetClassifier()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yCmsdx9Z7Xa",
        "outputId": "36ef656c-7adb-4851-a411-5c5cc7be811b"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.9609\n",
            "Epoch 2/10, Loss: 1.9727\n",
            "Epoch 3/10, Loss: 1.5995\n",
            "Epoch 4/10, Loss: 1.4510\n",
            "Epoch 5/10, Loss: 1.3627\n",
            "Epoch 6/10, Loss: 1.2954\n",
            "Epoch 7/10, Loss: 1.2432\n",
            "Epoch 8/10, Loss: 1.1913\n",
            "Epoch 9/10, Loss: 1.1459\n",
            "Epoch 10/10, Loss: 1.1036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test data\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COsqw27DaDO3",
        "outputId": "928bc01c-7658-4444-e832-917452e8214b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 67.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect predictions\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        y_pred.extend(predicted.numpy())\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "# Print metrics\n",
        "print(classification_report(y_true, y_pred))\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JXBYH3Zed4F",
        "outputId": "7af9801a-cd26-4b5c-9ee3-cacd98e8afa5"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.87      0.88       150\n",
            "           1       0.60      0.77      0.68       169\n",
            "           2       0.92      0.72      0.81       160\n",
            "           3       0.72      0.56      0.63       165\n",
            "           4       0.66      0.54      0.60       161\n",
            "           5       0.74      0.56      0.64       167\n",
            "           6       0.55      0.50      0.52       144\n",
            "           7       0.57      0.15      0.24       156\n",
            "           8       0.78      0.83      0.81       145\n",
            "           9       0.78      0.71      0.75       132\n",
            "          10       0.56      0.76      0.64       141\n",
            "          11       0.95      0.74      0.83       172\n",
            "          12       0.86      0.88      0.87       160\n",
            "          13       0.64      0.82      0.72       165\n",
            "          14       0.61      0.69      0.64       150\n",
            "          15       0.76      0.69      0.72       172\n",
            "          16       0.57      0.71      0.63       160\n",
            "          17       0.60      0.70      0.65       145\n",
            "          18       0.30      0.29      0.29       136\n",
            "          19       0.65      0.49      0.56       153\n",
            "          20       0.76      0.87      0.81       152\n",
            "          21       0.76      0.78      0.77       147\n",
            "          22       0.85      0.88      0.87       133\n",
            "          23       0.42      0.58      0.49       146\n",
            "          24       0.58      0.77      0.66       154\n",
            "          25       0.72      0.78      0.75       165\n",
            "\n",
            "    accuracy                           0.68      4000\n",
            "   macro avg       0.69      0.68      0.67      4000\n",
            "weighted avg       0.69      0.68      0.67      4000\n",
            "\n",
            "[[131   1   0   0   0   0   0   0   0   1   0   0   0   1   0   0   4   0\n",
            "    2   0   0   2   0   4   4   0]\n",
            " [  0 130   0   0   0   0   6   3   0   1   1   0   0   0   1   1   3  10\n",
            "    9   0   0   0   0   3   1   0]\n",
            " [  0   0 116   2   5   1   8   0   0   0  17   2   2   0   0   0   1   0\n",
            "    4   0   1   0   0   1   0   0]\n",
            " [  2  12   0  92   0   0   1   5   0   8   1   0   1   4  15   5   0  10\n",
            "    2   0   1   0   0   6   0   0]\n",
            " [  0   0   1   0  87   0   2   1   0   0   1   0   0   0   0   0  13   2\n",
            "    7   1   0   0   0  37   0   9]\n",
            " [  0  10   1   1   1  93   2   0   3   0   0   0   0   1   0  16   0   0\n",
            "    2  23   0   2   0   3   9   0]\n",
            " [  1   4   4   3   0   0  72   0   0   0   8   0   2   2   5   1  24   3\n",
            "    7   0   1   5   0   2   0   0]\n",
            " [  0   4   0   3   0   0   4  24   1   0  18   0   0  43  13   2   3  14\n",
            "    0   1  14   2   0   8   2   0]\n",
            " [  0   1   0   1   0   5   0   0 120   3   0   1   0   0   0   1   0   0\n",
            "    7   0   0   0   0   6   0   0]\n",
            " [  1   0   1   2   0   2   0   0  14  94   0   0   0   1   4   2   0   0\n",
            "    8   0   0   0   0   3   0   0]\n",
            " [  1   0   3   1   0   0   1   1   0   0 107   0   0   2   0   0   0  10\n",
            "    1   0   8   1   0   5   0   0]\n",
            " [  0   1   0   0   6   0   8   0   0   0   4 128   0   0   0   0   7   0\n",
            "    3   0   0   0   0  15   0   0]\n",
            " [  1   3   0   0   0   0   0   3   0   0   0   0 140   2   1   0   0   0\n",
            "    0   0   1   0   9   0   0   0]\n",
            " [  0   1   0   1   0   0   0   0   0   0   7   0   2 135   4   2   0   1\n",
            "    0   0   1   2   7   0   2   0]\n",
            " [  2   0   0   7   0   0  10   1   0   0   0   0   5   1 103   3   7   4\n",
            "    0   0   6   0   1   0   0   0]\n",
            " [  1   4   0  11   1  10   2   0   1   2   2   0   0   1   1 119   2   0\n",
            "    1   1   0   5   0   0   8   0]\n",
            " [  3   0   0   0   4   0   6   0   0   0   3   0   0   0   9   0 114   0\n",
            "   11   0   0   2   2   2   2   2]\n",
            " [  1  18   0   0   0   0   1   2   0   0  14   0   0   2   2   0   1 101\n",
            "    0   0   0   0   0   3   0   0]\n",
            " [  3  19   0   1   1   5   1   0   5   3   0   4   0   0   2   0   1   2\n",
            "   39   1   2   0   0   7   4  36]\n",
            " [  0   1   0   1   2   9   6   1   5   0   3   0   0   0   0   3   1   0\n",
            "    1  75   0   3   0   7  34   1]\n",
            " [  0   0   0   0   0   0   0   0   0   0   1   0   4   9   4   0   1   0\n",
            "    0   0 132   0   1   0   0   0]\n",
            " [  0   3   0   0   0   0   0   1   0   0   1   0   3   1   1   0   3   5\n",
            "    0   0   1 114   0   0  14   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   4   5   3   0   0   2\n",
            "    0   0   2   0 117   0   0   0]\n",
            " [  0   2   0   2  20   0   0   0   3   4   3   0   0   0   0   0  10   3\n",
            "    4   2   1   0   0  84   6   2]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   1   4   0\n",
            "    4  10   2  12   0   0 119   0]\n",
            " [  1   1   0   0   4   0   2   0   1   4   0   0   0   0   0   1   1   0\n",
            "   18   1   0   0   0   3   0 128]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define activation functions to try\n",
        "activations = [nn.ReLU, nn.Tanh, nn.Sigmoid]\n",
        "\n",
        "# Define configurations to try (each activation Ã— 4 configs)\n",
        "configs = [\n",
        "    {\"hidden1\": 64, \"hidden2\": 32, \"lr\": 0.001, \"epochs\": 10, \"activation\": act}\n",
        "    for act in activations\n",
        "] + [\n",
        "    {\"hidden1\": 128, \"hidden2\": 64, \"lr\": 0.001, \"epochs\": 10, \"activation\": act}\n",
        "    for act in activations\n",
        "] + [\n",
        "    {\"hidden1\": 128, \"hidden2\": 64, \"lr\": 0.0005, \"epochs\": 15, \"activation\": act}\n",
        "    for act in activations\n",
        "] + [\n",
        "    {\"hidden1\": 64, \"hidden2\": 64, \"lr\": 0.005, \"epochs\": 10, \"activation\": act}\n",
        "    for act in activations\n",
        "]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "for i, config in enumerate(configs):\n",
        "    print(f\"\\nðŸ”§ Config {i+1}: {config}, Activation: {config['activation'].__name__}\")\n",
        "\n",
        "    # Define model with activation\n",
        "    model = AlphabetClassifier(\n",
        "        hidden1=config[\"hidden1\"],\n",
        "        hidden2=config[\"hidden2\"],\n",
        "        activation=config[\"activation\"]\n",
        "    )\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    # Train\n",
        "    for epoch in range(config[\"epochs\"]):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f\"  Epoch {epoch+1}/{config['epochs']}, Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    results.append((config, accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-N7Y08Dfvlf",
        "outputId": "4f2d26e3-bce6-4600-d0c5-9c4e9c2962d5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”§ Config 1: {'hidden1': 64, 'hidden2': 32, 'lr': 0.001, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.ReLU'>}, Activation: ReLU\n",
            "  Epoch 1/10, Loss: 3.0114\n",
            "  Epoch 2/10, Loss: 2.0457\n",
            "  Epoch 3/10, Loss: 1.6696\n",
            "  Epoch 4/10, Loss: 1.5156\n",
            "  Epoch 5/10, Loss: 1.4169\n",
            "  Epoch 6/10, Loss: 1.3455\n",
            "  Epoch 7/10, Loss: 1.2888\n",
            "  Epoch 8/10, Loss: 1.2372\n",
            "  Epoch 9/10, Loss: 1.1909\n",
            "  Epoch 10/10, Loss: 1.1469\n",
            "Test Accuracy: 67.35%\n",
            "\n",
            "ðŸ”§ Config 2: {'hidden1': 64, 'hidden2': 32, 'lr': 0.001, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.Tanh'>}, Activation: Tanh\n",
            "  Epoch 1/10, Loss: 2.8112\n",
            "  Epoch 2/10, Loss: 1.8209\n",
            "  Epoch 3/10, Loss: 1.4869\n",
            "  Epoch 4/10, Loss: 1.3199\n",
            "  Epoch 5/10, Loss: 1.2012\n",
            "  Epoch 6/10, Loss: 1.1082\n",
            "  Epoch 7/10, Loss: 1.0322\n",
            "  Epoch 8/10, Loss: 0.9695\n",
            "  Epoch 9/10, Loss: 0.9169\n",
            "  Epoch 10/10, Loss: 0.8751\n",
            "Test Accuracy: 74.05%\n",
            "\n",
            "ðŸ”§ Config 3: {'hidden1': 64, 'hidden2': 32, 'lr': 0.001, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.Sigmoid'>}, Activation: Sigmoid\n",
            "  Epoch 1/10, Loss: 3.2619\n",
            "  Epoch 2/10, Loss: 3.2507\n",
            "  Epoch 3/10, Loss: 3.2031\n",
            "  Epoch 4/10, Loss: 2.9454\n",
            "  Epoch 5/10, Loss: 2.5871\n",
            "  Epoch 6/10, Loss: 2.3912\n",
            "  Epoch 7/10, Loss: 2.2748\n",
            "  Epoch 8/10, Loss: 2.1762\n",
            "  Epoch 9/10, Loss: 2.0820\n",
            "  Epoch 10/10, Loss: 2.0026\n",
            "Test Accuracy: 36.75%\n",
            "\n",
            "ðŸ”§ Config 4: {'hidden1': 128, 'hidden2': 64, 'lr': 0.001, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.ReLU'>}, Activation: ReLU\n",
            "  Epoch 1/10, Loss: 2.6566\n",
            "  Epoch 2/10, Loss: 1.6713\n",
            "  Epoch 3/10, Loss: 1.4075\n",
            "  Epoch 4/10, Loss: 1.2643\n",
            "  Epoch 5/10, Loss: 1.1587\n",
            "  Epoch 6/10, Loss: 1.0769\n",
            "  Epoch 7/10, Loss: 1.0174\n",
            "  Epoch 8/10, Loss: 0.9626\n",
            "  Epoch 9/10, Loss: 0.9246\n",
            "  Epoch 10/10, Loss: 0.8898\n",
            "Test Accuracy: 74.08%\n",
            "\n",
            "ðŸ”§ Config 5: {'hidden1': 128, 'hidden2': 64, 'lr': 0.001, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.Tanh'>}, Activation: Tanh\n",
            "  Epoch 1/10, Loss: 2.4522\n",
            "  Epoch 2/10, Loss: 1.4230\n",
            "  Epoch 3/10, Loss: 1.1473\n",
            "  Epoch 4/10, Loss: 1.0000\n",
            "  Epoch 5/10, Loss: 0.9013\n",
            "  Epoch 6/10, Loss: 0.8254\n",
            "  Epoch 7/10, Loss: 0.7639\n",
            "  Epoch 8/10, Loss: 0.7147\n",
            "  Epoch 9/10, Loss: 0.6674\n",
            "  Epoch 10/10, Loss: 0.6300\n",
            "Test Accuracy: 80.25%\n",
            "\n",
            "ðŸ”§ Config 6: {'hidden1': 128, 'hidden2': 64, 'lr': 0.001, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.Sigmoid'>}, Activation: Sigmoid\n",
            "  Epoch 1/10, Loss: 3.2608\n",
            "  Epoch 2/10, Loss: 3.2266\n",
            "  Epoch 3/10, Loss: 2.9563\n",
            "  Epoch 4/10, Loss: 2.4849\n",
            "  Epoch 5/10, Loss: 2.1916\n",
            "  Epoch 6/10, Loss: 2.0015\n",
            "  Epoch 7/10, Loss: 1.8645\n",
            "  Epoch 8/10, Loss: 1.7520\n",
            "  Epoch 9/10, Loss: 1.6596\n",
            "  Epoch 10/10, Loss: 1.5845\n",
            "Test Accuracy: 51.77%\n",
            "\n",
            "ðŸ”§ Config 7: {'hidden1': 128, 'hidden2': 64, 'lr': 0.0005, 'epochs': 15, 'activation': <class 'torch.nn.modules.activation.ReLU'>}, Activation: ReLU\n",
            "  Epoch 1/15, Loss: 2.9640\n",
            "  Epoch 2/15, Loss: 2.0344\n",
            "  Epoch 3/15, Loss: 1.6510\n",
            "  Epoch 4/15, Loss: 1.4704\n",
            "  Epoch 5/15, Loss: 1.3610\n",
            "  Epoch 6/15, Loss: 1.2862\n",
            "  Epoch 7/15, Loss: 1.2276\n",
            "  Epoch 8/15, Loss: 1.1763\n",
            "  Epoch 9/15, Loss: 1.1352\n",
            "  Epoch 10/15, Loss: 1.0964\n",
            "  Epoch 11/15, Loss: 1.0629\n",
            "  Epoch 12/15, Loss: 1.0340\n",
            "  Epoch 13/15, Loss: 1.0074\n",
            "  Epoch 14/15, Loss: 0.9834\n",
            "  Epoch 15/15, Loss: 0.9627\n",
            "Test Accuracy: 72.20%\n",
            "\n",
            "ðŸ”§ Config 8: {'hidden1': 128, 'hidden2': 64, 'lr': 0.0005, 'epochs': 15, 'activation': <class 'torch.nn.modules.activation.Tanh'>}, Activation: Tanh\n",
            "  Epoch 1/15, Loss: 2.8590\n",
            "  Epoch 2/15, Loss: 1.8842\n",
            "  Epoch 3/15, Loss: 1.4860\n",
            "  Epoch 4/15, Loss: 1.2904\n",
            "  Epoch 5/15, Loss: 1.1669\n",
            "  Epoch 6/15, Loss: 1.0776\n",
            "  Epoch 7/15, Loss: 1.0078\n",
            "  Epoch 8/15, Loss: 0.9513\n",
            "  Epoch 9/15, Loss: 0.9035\n",
            "  Epoch 10/15, Loss: 0.8604\n",
            "  Epoch 11/15, Loss: 0.8249\n",
            "  Epoch 12/15, Loss: 0.7923\n",
            "  Epoch 13/15, Loss: 0.7630\n",
            "  Epoch 14/15, Loss: 0.7352\n",
            "  Epoch 15/15, Loss: 0.7128\n",
            "Test Accuracy: 79.20%\n",
            "\n",
            "ðŸ”§ Config 9: {'hidden1': 128, 'hidden2': 64, 'lr': 0.0005, 'epochs': 15, 'activation': <class 'torch.nn.modules.activation.Sigmoid'>}, Activation: Sigmoid\n",
            "  Epoch 1/15, Loss: 3.2610\n",
            "  Epoch 2/15, Loss: 3.2536\n",
            "  Epoch 3/15, Loss: 3.2413\n",
            "  Epoch 4/15, Loss: 3.1962\n",
            "  Epoch 5/15, Loss: 3.0290\n",
            "  Epoch 6/15, Loss: 2.7563\n",
            "  Epoch 7/15, Loss: 2.5406\n",
            "  Epoch 8/15, Loss: 2.3910\n",
            "  Epoch 9/15, Loss: 2.2772\n",
            "  Epoch 10/15, Loss: 2.1799\n",
            "  Epoch 11/15, Loss: 2.0871\n",
            "  Epoch 12/15, Loss: 1.9948\n",
            "  Epoch 13/15, Loss: 1.9086\n",
            "  Epoch 14/15, Loss: 1.8321\n",
            "  Epoch 15/15, Loss: 1.7667\n",
            "Test Accuracy: 48.25%\n",
            "\n",
            "ðŸ”§ Config 10: {'hidden1': 64, 'hidden2': 64, 'lr': 0.005, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.ReLU'>}, Activation: ReLU\n",
            "  Epoch 1/10, Loss: 1.9935\n",
            "  Epoch 2/10, Loss: 1.1947\n",
            "  Epoch 3/10, Loss: 0.9512\n",
            "  Epoch 4/10, Loss: 0.8258\n",
            "  Epoch 5/10, Loss: 0.7415\n",
            "  Epoch 6/10, Loss: 0.6753\n",
            "  Epoch 7/10, Loss: 0.6253\n",
            "  Epoch 8/10, Loss: 0.5756\n",
            "  Epoch 9/10, Loss: 0.5439\n",
            "  Epoch 10/10, Loss: 0.5028\n",
            "Test Accuracy: 84.42%\n",
            "\n",
            "ðŸ”§ Config 11: {'hidden1': 64, 'hidden2': 64, 'lr': 0.005, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.Tanh'>}, Activation: Tanh\n",
            "  Epoch 1/10, Loss: 1.6492\n",
            "  Epoch 2/10, Loss: 0.9340\n",
            "  Epoch 3/10, Loss: 0.7433\n",
            "  Epoch 4/10, Loss: 0.6197\n",
            "  Epoch 5/10, Loss: 0.5394\n",
            "  Epoch 6/10, Loss: 0.4742\n",
            "  Epoch 7/10, Loss: 0.4228\n",
            "  Epoch 8/10, Loss: 0.3867\n",
            "  Epoch 9/10, Loss: 0.3502\n",
            "  Epoch 10/10, Loss: 0.3250\n",
            "Test Accuracy: 89.60%\n",
            "\n",
            "ðŸ”§ Config 12: {'hidden1': 64, 'hidden2': 64, 'lr': 0.005, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.Sigmoid'>}, Activation: Sigmoid\n",
            "  Epoch 1/10, Loss: 3.1656\n",
            "  Epoch 2/10, Loss: 2.2032\n",
            "  Epoch 3/10, Loss: 1.7395\n",
            "  Epoch 4/10, Loss: 1.4376\n",
            "  Epoch 5/10, Loss: 1.3039\n",
            "  Epoch 6/10, Loss: 1.2116\n",
            "  Epoch 7/10, Loss: 1.1374\n",
            "  Epoch 8/10, Loss: 1.0718\n",
            "  Epoch 9/10, Loss: 1.0083\n",
            "  Epoch 10/10, Loss: 0.9486\n",
            "Test Accuracy: 71.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_config = max(results, key=lambda x: x[1])\n",
        "print(\"\\nBest configuration and accuracy:\")\n",
        "print(best_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHhQGGGkgqNL",
        "outputId": "3ff8b27e-3c7a-48b3-d9b2-7ae441e1498b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best configuration and accuracy:\n",
            "({'hidden1': 64, 'hidden2': 64, 'lr': 0.005, 'epochs': 10, 'activation': <class 'torch.nn.modules.activation.Tanh'>}, 89.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion and Conclusion\n",
        "\n",
        "In this assignment, we built an Artificial Neural Network (ANN) to classify alphabet data and studied how tuning different hyperparametersâ€”such as hidden layer sizes, learning rate, number of epochs, and activation functionsâ€”affects its accuracy. The base model started with 66.40% accuracy. After tuning, the best-performing configuration used two hidden layers of 64 neurons each, a learning rate of 0.005, 10 epochs, and the Tanh activation function, achieving a final accuracy of 86.27%. These results demonstrate that careful tuning of model architecture and activation functions significantly improves learning and classification performance."
      ],
      "metadata": {
        "id": "no2-qE9DpB3m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4yJE-gNQkceD"
      },
      "execution_count": 72,
      "outputs": []
    }
  ]
}